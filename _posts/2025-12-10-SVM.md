## User Classification using Support-Margin SVM

빅데이터 수학 기말 과제 <br>

**Author : 고건우, 김민성, 손승현** <br>

<br>

### Introduction

유저 분류는 사용자 행동 데이터를 기반하여 분류하는 문제로, 서비스 개선과 의사결정 과정에서 중요한 역할을 한다. 이런 분류 문제에서는 분류할 두 클래스 간의 경계를 명확히 정의해서 일반화 성능을 이끌어 내는 것이 중요하다. <br>

본 프로젝트에서 사용하는 Support Vector Machinie (SVM)은 Margin 최대화를 이용한 초평면을 학습하여 분류하는 기계학습 방법으로 유저 분류를 수행하고 성능을 평가한다. <br>

### 1. Data Characteristics Analysis

분류를 하기 전에 데이터의 feature와 구성을 확인해보자

```python
import pandas as pd

df = pd.read_csv("data.csv")
print(df.head())
```

**output :**

feature 3개와 label이 주어졌음을 알 수 있고, 이를 통해 3차원 상의 svm을 수행해야 하는 것을 알 수 있다.

### 2. Support Vector Machine

**서포트 벡터 머신(Support Vector Machine, SVM)** 은 고차원 데이터에서도 강력한 분류 성능을 보이는 대표적인 지도학습 기법이다. <br>

Random forest, NeuralNet과 더불어 가장 많이 사용되는 ML기법으로 관련 전공자라면 한번쯤은 들어봤을법한 기법이다. <br>

SVM의 핵심 아이디어는 주어진 데이터들을 **가장 넓은 마진(margin)** 을 확보할 수 있도록 분리하는 초평면(hyperplane)을 찾는 것이다. <br>

이때 초평면과 가장 가까이 위치한 데이터 점들을 **서포트 벡터(support vectors)** 라 부르며, 이들이 결정 경계(decision boundary)를 정의하는 데 핵심적인 역할을 한다. <br>

#### 2.1 Description of SVM

SVM의 핵심은 고차원에서 두개의 그룹을 가장 넓게 분리하는 가상의 초평면(hyperplane)을 찾아내는 것이다.

위 그림에서 각 그룹에서 가상의 구분선 까지의 거리가 가장 짧은 데이터를 **support vector** 라고 부른다.<br>

#### 2.2 Mathematical Principles of SVM

SVM의 결과 목표가 다음과 같다고 가정해보자

지금은 2차원 데이터이기 때문에 hyperplane은 1차원 직선이고 다음과 같이 쓸 수 있다

$$
w^Tx + b = 0
$$

이를 보기쉽게 element 표현으로 적으면 다음과 같이도 표현할 수 있다. (3차원 이므로 basis 3개)

$$
w_1x_1 + w_2x_2 + w_3x_3 + b = 0
$$

각 데이터의 범주와 결정경계와의 거리가 c 라고 가정할때 범주를 다음과 같이 쓸 수 있다. <br>

빨간데이터 :

$$
w_1x_1 + w_2x_2 + w_3x_3 + b > c
$$

파란데이터:

$$
w_1x_1 + w_2x_2 + w_3x_3 + b \ㄱㄷ c
$$