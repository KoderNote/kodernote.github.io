---
layout: post

title: Calculus, Gradient and Directional Derivative

tags: [Calculus , CSE, Data Science, AI, Optimization]

feature-img: "assets/img/calculus/gradient.png"

thumbnail: "assets/img/calculus/gradient.png"

categories: CSE, AI, Calculus, Optimization, Gradient, Directional Derivative
---

## Gradient & Directional Derivative

경도(gradient)와 방향 도함수(directional derivative)는 다변수에서 미분과 같은 존재이다. <br>

Univariate function에서 미분이 필수적인 과정이듯이, gradient와 directional derivative 또한 필수적으로 숙지 해야만 한다. <br>

<br>

### 1. 경도 (Gradient)

z=f(x,y)가 점 (x0​,y0​)에서 미분가능할 때, (fx​,fy​)(x0​,y0​)​을 f의 **경도(gradient)** 라 하고 다음과 같이 나타낸다.

$$
∇f(x₀, y₀) \quad  또는 \quad  grad f
$$

앞에 역삼각형 모양 기호 ∇는 nabla기호로 수학 연산자에서는 del이라고 불린다. <br>

앞으로 많이 접하게 될 기호이다. <br>

n 변수 함수에 대하여 ∇f는 다음과 같은 의미를 지닌다.

$$
∇f = \left( \frac{\partial f}{\partial x₁}, \frac{\partial f}{\partial x₂}, \dots, \frac{\partial f}{\partial xₙ} \right)
$$

예를 들어 f(x,y) = x^2 + y^2 + xy − 1의 점 (1,2)에서의 경도는 다음과 같은 과정으로 구할 수 있다.

$$
f(x,y) = x^2 + y^2 + xy - 1 \\
∇f(x,y) = (2x + y,\; 2y + x) \\
∇f(1,2) = (4, 5)
$$

참고로 추후 gradient의 기하학적 해석에 대해 설명하지만, 가끔 그라디언트는 법선벡터 이렇게 숙지하고 있는 경우가 있다. <br>

하지만 이는 잘못된 생각이며, 그라디언트는 그냥 그라디언트지 법선벡터라고 일반화 시키는 것은 잘못된 방향성이다. <br>

굳이 따지면 음함수꼴 (Inplicit form)에서의 gradient는 법선벡터(normal vector)가 맞지만, 양함수꼴(Explicit form)에서의 gradient는 가장 가파르게 증가하는 방향을 의미한다.

<br>

<br>

### 2. 방향 도함수 (Directional derivative)

z = f(x,y)에서 P0​(x0​,y0​)를 xy 평면상의 고정된 점이라 하고 직선 l이 점 P0​(x0​,y0​)을 통과하는 것으로 하자. 점 P(x,y)가 직선 l을 따라서 움직이는 점이라 하면 이에 따라 z = f(x,y)는 곡면상에 곡선 C를 그리게 된다. <br>

점 P(x,y)에 대응하는 곡선 C 상의 점을 Q라 하고 P0​와 P의 거리를 h라 하면, h에 관한 Q의 z값의 변화를 생각해 볼 수 있을 것이다.

이를 위해 u=(u1​,u2​)를 P0​를 시발점으로 하고 P를 향한 단위벡터라 하면, 다음과 같이 나타낼 수 있다.

$$
\overrightarrow{P_0 P} = h \vec{u} 
\;\;\Leftrightarrow\;\;
(x - x_0, y - y_0) = h(u_1, u_2) 
\;\;\Leftrightarrow\;\;
x = x_0 + h u_1,\; y = y_0 + h u_2
$$

이때 z=f(x,y)에 대하여 u=(u1​,u2​)으로의 방향 도함수는 다음과 같다.

$$
D_{\vec{u}} f(x_0,y_0) 
= \lim_{h \to 0} 
\frac{ f(x_0 + h u_1,\, y_0 + h u_2) - f(x_0,y_0) }{h}
$$

그림을 보면 쉽게 이해할 수 있다.

<br>

만약 z=f(x,y)가 미분가능한 함수라면 모든 방향 도함수는 존재한다. 이때 다음과 같이 계산한다.

$$
D_{\vec{u}} f(x_0,y_0) 
= \nabla f(x_0,y_0) \cdot \vec{u}
$$

마찬가지로 미분가능한 3변수 함수 u=f(x,y,z)에서도 모든 방향 도함수는 존재하며 다음과 같이 계산한다.

$$
D_{\vec{u}} f(x_0,y_0,z_0) 
= \nabla f(x_0,y_0,z_0) \cdot \vec{u}
$$

<br>

쉽게 설명하면 Explicit form에서의 gradient에 방향벡터를 내적하는 것과 같다. <br>

<br>

예제와 함께 방향도함수 계산을 해보자.<br>

<br>

#### 문제 1 (Basic)

점 (4/π​,4/π​)에서 θ=4/π​ 방향으로의 다음 함수의 directional derivative를 구하면?

$$
f(x,y) = xsiny
$$

#### 문제 2 (Normal)

함수

$$
f(x,y) =
\begin{cases} 
x^2 + y - x e^y & (x \neq 0) \\[6pt]
0 & (x = 0)
\end{cases}
$$

에 대하여

$$
\nabla f(0,0) = (\alpha, \beta)
$$

라고 할때 α+β 의 값은?

### 문제 3 (Advanced)

곡면

$$
f(x,y)=x^2+y^2,\qquad
-\sqrt{3}\,x + y = -\sqrt{3}+1
$$

을 다음 평면에 대하여 잘랐을 때,

$$
-\sqrt{3}\,x + y = -\sqrt{3} + 1
$$

점 (1,1,2)에서 **곡면이 잘린 양의 방향**으로 접선의 기울기를 구하면?

### 문제 4 (Advanced)

함수 f:R^2 → R가 (0,0)의 근방에서 미분가능하고 <br>

벡터

$$
v = \left(\frac{2}{\sqrt{5}}, \frac{1}{\sqrt{5}}\right), 
\quad 
w = \left(-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right)
$$

에 대한 directional derivative가 다음과 같을때

$$
D_v f(0,0) = \frac{3}{\sqrt{5}}, 
\quad 
D_w f(0,0) = -\frac{1}{\sqrt{2}}
$$

벡터

$$
u = \left(\frac{3}{\sqrt{10}}, \frac{1}{\sqrt{10}}\right)
$$

에 대한 다음 방향도함수 값은?

$$
D_u f(0,0)
$$